# Ex√©cution Parall√®le

Le code a √©t√© modifi√© pour supporter l'**ex√©cution parall√®le** des calculs sur diff√©rentes dimensions, ce qui acc√©l√®re consid√©rablement l'analyse.

## üöÄ Comment lancer

### Pr√©requis

Installer les d√©pendances (une seule fois) :

```bash
# Option 1 : Installation directe
pip3 install numpy scipy matplotlib

# Option 2 : Avec environnement virtuel (recommand√©)
python3 -m venv venv
source venv/bin/activate
pip install numpy scipy matplotlib
```

### Test rapide (recommand√©)

Pour v√©rifier que tout fonctionne :

```bash
python3 test_parallel.py
```

Ce script teste l'ex√©cution parall√®le sur 3 dimensions (10, 20, 50) avec 2 algorithmes. Dur√©e : ~1-2 minutes.

### Analyse compl√®te

Pour l'analyse compl√®te sur toutes les dimensions :

```bash
python3 run_dimension_analysis.py
```

Ce script :
- Teste 9 dimensions : [2, 4, 8, 16, 32, 64, 128, 256, 512]
- Compare 6 algorithmes : Alg3, Alg5, Alg7, Alg8_m1, Alg8_m2, Alg8_m30
- **S'ex√©cute en parall√®le** sur tous les CPUs disponibles
- G√©n√®re le graphique : `results/iid_time_vs_dimension.png`

Dur√©e estim√©e : D√©pend du nombre de CPUs (avec 8 CPUs : ~10-15 minutes)

## ‚öôÔ∏è Comment √ßa marche

### Parall√©lisation

Le code utilise `multiprocessing.Pool` pour traiter **chaque dimension en parall√®le** :

```python
plot_autocorr_time_vs_dimension(
    dimensions=[10, 20, 50, 100, 200],
    n_jobs=-1  # -1 = utilise tous les CPUs disponibles
)
```

Options pour `n_jobs` :
- `-1` : Utilise tous les CPUs (recommand√©)
- `4` : Utilise 4 CPUs
- `1` : Ex√©cution s√©quentielle (pas de parall√©lisation)

### Calcul du temps i.i.d.

Pour chaque dimension et chaque algorithme, le code calcule :

```
œÑ = 1 / (1 - œÅ)                    # Temps d'autocorr√©lation
temps_2_iid = 2 √ó œÑ √ó temps_par_iter  # Temps pour 2 √©chantillons ind√©pendants
```

o√π :
- `œÅ` = autocorr√©lation de lag-1 (sur k ou Œ∏‚ÇÅ)
- `temps_par_iter` = temps moyen par it√©ration MCMC en ms

## üìä R√©sultats

Les r√©sultats sont sauvegard√©s dans `results/` :

- `iid_time_vs_dimension.png` : Graphique principal
- `results_dim{n}.pkl` : R√©sultats d√©taill√©s pour chaque dimension
- `results_dim{n}.json` : R√©sum√© en JSON

## üîß Personnalisation

Vous pouvez modifier `run_dimension_analysis.py` pour :

### Changer les dimensions test√©es

```python
dimensions = [10, 50, 100, 500]  # Vos dimensions
```

### Changer les algorithmes

```python
algorithms = ['Alg7', 'Alg8_m2']  # Seulement 2 algos rapides
```

### Ajuster les it√©rations

```python
iid_times_k = plot_autocorr_time_vs_dimension(
    dimensions=dimensions,
    n_iter=2000,   # Plus d'it√©rations = meilleure pr√©cision
    burn_in=200,
    n_jobs=-1
)
```

### D√©sactiver la parall√©lisation

```python
n_jobs=1  # Ex√©cution s√©quentielle
```

## üìà Exemple de sortie

```
================================================================================
Dimension Analysis: Time for 2 i.i.d. samples vs Data Dimension
================================================================================

Using 8 parallel processes

================================================================================
Testing dimension: 64
================================================================================
Running Algorithm 3...
Running Algorithm 5...
...

Time for 2 i.i.d. samples (ms) - autocorrelation on k:
--------------------------------------------------------------------------------
Algorithm      n=2          n=4          n=8          n=16         ...
Alg3           45.23        89.12        178.45       356.89       ...
Alg5           52.34        104.67       209.34       418.68       ...
...
```

## üêõ Troubleshooting

### Erreur "ModuleNotFoundError: No module named 'scipy'"

Installez les d√©pendances :
```bash
pip3 install scipy matplotlib numpy
```

### Probl√®me avec multiprocessing sur Windows

Sur Windows, assurez-vous que le code est dans un bloc `if __name__ == "__main__":` (d√©j√† fait).

### Utilisation excessive de RAM

R√©duisez le nombre de processus parall√®les :
```python
n_jobs=4  # Au lieu de -1
```

Ou r√©duisez le nombre d'it√©rations :
```python
n_iter=500  # Au lieu de 1000
```

## üí° Conseils

1. **Commencez par le test** : `python3 test_parallel.py`
2. **Surveillez l'utilisation CPU** : Vous devriez voir tous vos CPUs √† ~100%
3. **Pour les grandes dimensions** : Consid√©rez r√©duire le nombre d'algorithmes
4. **Sauvegarde** : Les r√©sultats interm√©diaires sont sauvegard√©s au fur et √† mesure

## üéØ Performance

Gain de temps avec parall√©lisation (exemple avec 8 CPUs) :

| Ex√©cution | Temps estim√© |
|-----------|--------------|
| S√©quentielle (n_jobs=1) | ~80 minutes |
| Parall√®le (n_jobs=-1, 8 CPUs) | ~10-15 minutes |

**Acc√©l√©ration : ~5-6x**
